{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Migrate from v7.7.2 to v7.8.0\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. Start a MongoDB server on your local machine (or in a Docker container) and ensure it does **not** contain a database named `nmdc`.\n",
    "1. Create a file named `.notebook.env` in the same folder as this notebook. \n",
    "    - You can copy the `.notebook.env.example` file as a starting point.\n",
    "2. Customize the values in the `.notebook.env` file to reflect your situation.\n",
    "    - For the origin MongoDB server, use root credentials since this notebook will be manipulating user roles.\n",
    "3. Run the cells in this notebook in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the third-party Python packages upon which this notebook depends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pymongo python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the standard and third-party Python packages upon which this notebook depends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pformat\n",
    "from pathlib import Path\n",
    "from tempfile import NamedTemporaryFile\n",
    "import re\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the notebook configuration parameters from the `.notebook.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file_path = \"./.notebook.env\"\n",
    "if not Path(cfg_file_path).is_file():\n",
    "    raise FileNotFoundError(\"Config file not found.\")\n",
    "\n",
    "cfg = dotenv_values(cfg_file_path)\n",
    "\n",
    "origin_mongo_username: str = cfg[\"ORIGIN_MONGO_USER\"]\n",
    "origin_mongo_password: str = cfg[\"ORIGIN_MONGO_PASS\"]\n",
    "origin_mongo_host: str = cfg[\"ORIGIN_MONGO_HOST\"]\n",
    "origin_mongo_port: int = int(cfg[\"ORIGIN_MONGO_PORT\"])\n",
    "\n",
    "transformer_mongo_username: str = cfg[\"TRANSFORMER_MONGO_USER\"]\n",
    "transformer_mongo_password: str = cfg[\"TRANSFORMER_MONGO_PASS\"]\n",
    "transformer_mongo_host: str = cfg[\"TRANSFORMER_MONGO_HOST\"]\n",
    "transformer_mongo_port: int = int(cfg[\"TRANSFORMER_MONGO_PORT\"])\n",
    "\n",
    "mongodump: str = cfg[\"PATH_TO_MONGODUMP_BINARY\"]\n",
    "mongorestore: str = cfg[\"PATH_TO_MONGORESTORE_BINARY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate MongoDB configuration files.\n",
    "\n",
    "You'll use these files file with `mongodump` and `mongorestore` to prevent the associated CLI commands from containing the passwords in plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary file in the notebook's folder, containing the origin MongoDB password.\n",
    "origin_mongo_config_file = NamedTemporaryFile(delete=False, dir=str(Path.cwd()), prefix=\"tmp.origin_mongo_config.\")\n",
    "origin_mongo_config_file.write(bytes(f\"password: {origin_mongo_password}\", \"utf-8\"))\n",
    "origin_mongo_config_file.close()\n",
    "origin_mongo_config_file_path: str = origin_mongo_config_file.name\n",
    "\n",
    "# Create temporary file in the notebook's folder, containing the transformer MongoDB password.\n",
    "transformer_mongo_config_file = NamedTemporaryFile(delete=False, dir=str(Path.cwd()), prefix=\"tmp.transformer_mongo_config.\")\n",
    "transformer_mongo_config_file.write(bytes(f\"password: {transformer_mongo_password}\", \"utf-8\"))\n",
    "transformer_mongo_config_file.close()\n",
    "transformer_mongo_config_file_path: str = transformer_mongo_config_file.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MongoDB clients\n",
    "\n",
    "Create MongoDB clients you can use to access the \"origin\" MongoDB server (i.e. the one containing the database you want to migrate) and the \"transformer\" MongoDB server (i.e. the one you want to use to perform the data transformations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB client for origin MongoDB server.\n",
    "origin_mongo_client = pymongo.MongoClient(\n",
    "    username=origin_mongo_username,\n",
    "    password=origin_mongo_password,\n",
    "    host=origin_mongo_host,\n",
    "    port=origin_mongo_port,\n",
    "    directConnection=True,\n",
    ")\n",
    "\n",
    "# MongoDB client for transformer MongoDB server.\n",
    "transformer_mongo_client = pymongo.MongoClient(\n",
    "    username=transformer_mongo_username,\n",
    "    password=transformer_mongo_password,\n",
    "    host=transformer_mongo_host,\n",
    "    port=transformer_mongo_port,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disable writing to the origin MongoDB database\n",
    "\n",
    "To disable writing to the database, I will eventually set all users' roles (except the admin user) to `read` (i.e. read-only) with respect to the database. Before I carry out that plan, though, I will store the original users for future reference (so I can restore their original roles later).\n",
    "\n",
    "Note: `pymongo` does not offer [`db.getUsers()`](https://www.mongodb.com/docs/manual/reference/method/db.getUsers/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result: dict = origin_mongo_client[\"admin\"].command(\"usersInfo\")\n",
    "users_initial = result[\"users\"]\n",
    "\n",
    "# Create temporary file in the notebook's folder, containing the initial users.\n",
    "users_file = NamedTemporaryFile(delete=False, dir=str(Path.cwd()), prefix=\"tmp.origin_users_initial.\")\n",
    "users_file.write(bytes(pformat(users_initial), \"utf-8\"))\n",
    "users_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've stored their original roles, I'll convert every `readWrite` role (with respect to the `nmdc` database) into just plain `read`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users_initial:\n",
    "\n",
    "    break  # Abort! TODO: Remove me when I'm ready to run this notebook for real.\n",
    "\n",
    "    if any((role[\"db\"] == \"nmdc\") for role in user[\"roles\"]):\n",
    "        origin_mongo_client[\"admin\"].command(\"grantRolesToUser\", user[\"user\"], roles=[{ \"role\": \"read\", \"db\": \"nmdc\" }])\n",
    "        origin_mongo_client[\"admin\"].command(\"revokeRolesFromUser\", user[\"user\"], roles=[{ \"role\": \"readWrite\", \"db\": \"nmdc\" }])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump the necessary collections from the origin database\n",
    "\n",
    "In this case, I'll dump the `study_set` collection only.\n",
    "\n",
    "References:\n",
    "- https://www.mongodb.com/docs/database-tools/mongodump/\n",
    "- https://www.mongodb.com/docs/database-tools/mongodump/#std-option-mongodump.--config (`--config` option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_dump_folder_path = \"./mongodump.origin.out\"\n",
    "\n",
    "# Dump the database from the origin MongoDB server.\n",
    "!{mongodump} \\\n",
    "  --config=\"{origin_mongo_config_file_path}\" \\\n",
    "  --host=\"{origin_mongo_host}\" \\\n",
    "  --port=\"{origin_mongo_port}\" \\\n",
    "  --authenticationDatabase=\"admin\" \\\n",
    "  --username=\"{origin_mongo_username}\" \\\n",
    "  --db=\"nmdc\" \\\n",
    "  --gzip \\\n",
    "  --collection=\"study_set\" \\\n",
    "  --out=\"{origin_dump_folder_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore the database into the transformer MongoDB server\n",
    "\n",
    "References:\n",
    "- https://www.mongodb.com/docs/database-tools/mongorestore/\n",
    "- https://www.mongodb.com/docs/database-tools/mongorestore/#std-option-mongorestore.--config (`--config` option)\n",
    "- https://www.mongodb.com/docs/database-tools/mongorestore/#std-option-mongorestore.--drop (`--drop` to drop the existing collection)\n",
    "- https://www.mongodb.com/docs/database-tools/mongorestore/#std-option-mongorestore.--preserveUUID (`--preserveUUID` to use the existing UUIDs from the dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the database to the transformer MongoDB server.\n",
    "!{mongorestore} \\\n",
    "  --config=\"{transformer_mongo_config_file_path}\" \\\n",
    "  --host=\"{transformer_mongo_host}\" \\\n",
    "  --port=\"{transformer_mongo_port}\" \\\n",
    "  --username=\"{transformer_mongo_username}\" \\\n",
    "  --gzip \\\n",
    "  --drop --preserveUUID \\\n",
    "  --dir=\"{origin_dump_folder_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the database\n",
    "\n",
    "Now that the transformer database contains a copy of the subject database, we can transform it there.\n",
    "\n",
    "Source: https://github.com/microbiomedata/nmdc-schema/blob/13acf18c9e3b92b39bf67db9d17c66f190575c9d/nmdc_schema/migration_recursion.py#L21C1-L36C27\n",
    "- Replaced `logger` calls with `print` calls\n",
    "- Removed unused CURIE regex pattern\n",
    "- Removed commented-out line\n",
    "- Added import for `re`\n",
    "\n",
    "References:\n",
    "- https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html#pymongo.collection.Collection.replace_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# <copy_pasted_snippet from=\"https://github.com/microbiomedata/nmdc-schema/blob/13acf18c9e3b92b39bf67db9d17c66f190575c9d/nmdc_schema/migration_recursion.py#L21C1-L36C27\">\n",
    "doi_url_pattern = r'^https?:\\/\\/[a-zA-Z\\.]+\\/10\\.'\n",
    "\n",
    "def migrate_studies_7_7_2_to_7_8(retrieved_study):\n",
    "    print(f\"Starting migration of {retrieved_study['id']}\")\n",
    "    if \"doi\" in retrieved_study:\n",
    "        match = re.search(doi_url_pattern, retrieved_study[\"doi\"]['has_raw_value'])\n",
    "        if match:\n",
    "            start_index = match.end()\n",
    "            as_curie = f\"doi:10.{retrieved_study['doi']['has_raw_value'][start_index:]}\"\n",
    "            retrieved_study[\"award_dois\"] = [as_curie]\n",
    "        del retrieved_study[\"doi\"]\n",
    "    return retrieved_study\n",
    "# </copy_pasted_snippet>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a transformed version of each study in the transformer database.\n",
    "transformed_studies = []\n",
    "for study in transformer_mongo_client[\"nmdc\"][\"study_set\"].find():\n",
    "    transformed_study = migrate_studies_7_7_2_to_7_8(study)\n",
    "    transformed_studies.append(transformed_study)\n",
    "    print(study)\n",
    "    print(transformed_study)\n",
    "\n",
    "# Replace the original versions with the transformed versions of themselves (in the transformer database).\n",
    "for transformed_study in transformed_studies:\n",
    "    transformer_mongo_client[\"nmdc\"][\"study_set\"].replace_one({\"id\": {\"$eq\": transformed_study[\"id\"]}}, transformed_study)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the transformed database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump the transformed database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_dump_folder_path = \"./mongodump.transformer.out\"\n",
    "\n",
    "# Dump the database from the transformer MongoDB server.\n",
    "!{mongodump} \\\n",
    "  --config=\"{transformer_mongo_config_file_path}\" \\\n",
    "  --host=\"{transformer_mongo_host}\" \\\n",
    "  --port=\"{transformer_mongo_port}\" \\\n",
    "  --authenticationDatabase=\"admin\" \\\n",
    "  --username=\"{transformer_mongo_username}\" \\\n",
    "  --db=\"nmdc\" \\\n",
    "  --gzip \\\n",
    "  --out=\"{transformer_dump_folder_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put the transformed data into the origin MongoDB server\n",
    "\n",
    "In the case of this migration, given how focused the transformation was (i.e. only the `study_set` collection was affected), I will restore **only** the `study_set` collection to the origin server.\n",
    "\n",
    "References:\n",
    "- https://www.mongodb.com/docs/database-tools/mongorestore/#std-option-mongorestore.--nsInclude (`--nsInclude` to specify which collections to affect)\n",
    "- https://www.mongodb.com/docs/database-tools/mongorestore/#std-option-mongorestore.--dryRun (`--dryRun` can be used to preview the outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original `study_set` collection from the origin server,\n",
    "# and restore the transformed `study_set` collection into its place.\n",
    "!{mongorestore} \\\n",
    "  --config=\"{origin_mongo_config_file_path}\" \\\n",
    "  --host=\"{origin_mongo_host}\" \\\n",
    "  --port=\"{origin_mongo_port}\" \\\n",
    "  --username=\"{origin_mongo_username}\" \\\n",
    "  --gzip \\\n",
    "  --verbose \\\n",
    "  --dir=\"{transformer_dump_folder_path}\" \\\n",
    "  --nsInclude=\"nmdc.study_set\" \\\n",
    "  --drop --preserveUUID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've restored the database, I'll restore the original user roles (with respect to the `nmdc` database)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users_initial:\n",
    "\n",
    "    break  # Abort! TODO: Remove me when I'm ready to run this notebook for real.\n",
    "\n",
    "    if any((role[\"db\"] == \"nmdc\" and role[\"role\"] == \"readWrite\") for role in user[\"roles\"]):\n",
    "        origin_mongo_client[\"admin\"].command(\"grantRolesToUser\", user[\"user\"], roles=[{ \"role\": \"readWrite\", \"db\": \"nmdc\" }])\n",
    "        origin_mongo_client[\"admin\"].command(\"revokeRolesFromUser\", user[\"user\"], roles=[{ \"role\": \"read\", \"db\": \"nmdc\" }])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About db.fsyncLock() and db.fsyncUnlock()\n",
    "\n",
    "I chose not to use `db.fsyncLock()`/`db.fsyncUnlock()` as the method of disabling/re-enabling write access, because I want to be able to `mongorestore` a database while write access is still disabled. `db.fsyncLock()` would have disabled write access at the `mongod` level, preventing database-level write operations (but still allowing a system administrator to \"backup\" database **files** via `cp`, `scp`, `tar`, etc.\n",
    "\n",
    "Reference: https://www.mongodb.com/docs/manual/reference/method/db.fsyncLock/#mongodb-method-db.fsyncLock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "You may want to manually delete the `.tmp.*` files that this notebook created in its folder. Some of them contain MongoDB passwords."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
