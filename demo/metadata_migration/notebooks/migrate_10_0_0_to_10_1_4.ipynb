{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Migrate MongoDB database from `nmdc-schema` `v10.0.0` to `v10.1.4`\n",
    "\n",
    "- TODO: Disable read/write access to the origin database during the migration process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ad4ab",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d358ba",
   "metadata": {},
   "source": [
    "### 1. Determine MongoDB collections involved.\n",
    "\n",
    "Here, you'll determine which MongoDB collections will be used as part of this migration.\n",
    "\n",
    "1. In the [`nmdc-schema` repo](https://github.com/microbiomedata/nmdc-schema/tree/main/nmdc_schema/migrators), go to the `nmdc_schema/migrators` directory and open the Python module whose name contains the two schema versions involved with this migration. For example, if migrating from schema version `A.B.C` to `X.Y.Z`, open the module named `migrator_from_A_B_C_to_X_Y_Z.py`.\n",
    "2. Determine the collections that are accessed—whether for reading or for writing—by that module. **This is currently a manual process.**\n",
    "3. Add their names to the `COLLECTION_NAMES` Python list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09966b0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T20:22:46.752014Z",
     "start_time": "2024-03-11T20:22:46.747606Z"
    }
   },
   "outputs": [],
   "source": [
    "COLLECTION_NAMES: list[str] = [\n",
    "    \"data_object_set\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f351e8",
   "metadata": {},
   "source": [
    "### 2. Coordinate with stakeholders.\n",
    "\n",
    "Identify the people that read/write to those collections, or that maintain software that reads/writes to those collection. You can view a list of stakeholders in `./stakeholders.md`. \n",
    "\n",
    "Once you have identified those people; coordinate with them to agree on a time window for the migration. You can contact them via Slack, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233a35c3",
   "metadata": {},
   "source": [
    "### 3. Set up environment.\n",
    "\n",
    "Here, you'll prepare an environment for running this notebook.\n",
    "\n",
    "1. Start a **MongoDB server** on your local machine (and ensure it does **not** already contain a database named `nmdc`).\n",
    "    1. You can start a [Docker](https://hub.docker.com/_/mongo)-based MongoDB server at `localhost:27055` by running this command (this MongoDB server will be accessible without a username or password).\n",
    "       ```shell\n",
    "       docker run --rm --detach --name mongo-migration-transformer -p 27055:27017 mongo:6.0.4\n",
    "       ```\n",
    "2. Create and populate a **notebook configuration file** named `.notebook.env`.\n",
    "    1. You can use `.notebook.env.example` as a template:\n",
    "       ```shell\n",
    "       $ cp .notebook.env.example .notebook.env\n",
    "       ```\n",
    "3. Create and populate the two **MongoDB configuration files** that this notebook will use to connect to the \"origin\" and \"transformer\" MongoDB servers. The \"origin\" MongoDB server is the one that contains the database you want to migrate; and the \"transformer\" MongoDB server is the one you want to use to perform the data transformations. In practice, the \"origin\" MongoDB server is typically a remote server, and the \"transformer\" MongoDB server is typically a local server.\n",
    "    1. You can use `.mongo.yaml.example` as a template:\n",
    "       ```shell\n",
    "       $ cp .mongo.yaml.example .mongo.origin.yaml\n",
    "       $ cp .mongo.yaml.example .mongo.transformer.yaml\n",
    "       ```\n",
    "       > When populating the file for the origin MongoDB server, use credentials that have **both read and write access** to the `nmdc` database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69937b18",
   "metadata": {},
   "source": [
    "## Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe81196a",
   "metadata": {},
   "source": [
    "### Install Python dependencies\n",
    "\n",
    "In this step, you'll [install](https://saturncloud.io/blog/what-is-the-difference-between-and-in-jupyter-notebooks/) the Python packages upon which this notebook depends.\n",
    "\n",
    "> Note: If the output of this cell says \"Note: you may need to restart the kernel to use updated packages\", restart the kernel (not the notebook) now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a0af308c3185b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "%pip install nmdc-schema==10.1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a407c354",
   "metadata": {},
   "source": [
    "### Import Python dependencies\n",
    "\n",
    "Import the Python objects upon which this notebook depends.\n",
    "\n",
    "> Note: One of the `import` statements is specific to this migration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbecd561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T00:46:18.764498Z",
     "start_time": "2024-03-05T00:46:18.202997Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stdlib packages:\n",
    "from copy import deepcopy\n",
    "\n",
    "# Third-party packages:\n",
    "import pymongo\n",
    "from jsonschema import Draft7Validator, ValidationError\n",
    "from nmdc_schema.nmdc_data import get_nmdc_jsonschema_dict\n",
    "from nmdc_schema.migrators.adapters.mongo_adapter import MongoAdapter\n",
    "\n",
    "from nmdc_schema.migrators.migrator_from_10_0_0_to_10_1_2 import Migrator  # note: the migrator to 10.1.2 was introduced in schema version 10.1.4\n",
    "\n",
    "# First-party packages:\n",
    "from helpers import Config\n",
    "from bookkeeper import Bookkeeper, MigrationEvent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b20ff4",
   "metadata": {},
   "source": [
    "### Parse configuration files\n",
    "\n",
    "Parse the notebook and Mongo configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "\n",
    "# Define some aliases we can use to make the shell commands in this notebook easier to read.\n",
    "mongodump = cfg.mongodump_path\n",
    "mongorestore = cfg.mongorestore_path\n",
    "\n",
    "# Perform a sanity test of the application paths.\n",
    "!{mongodump} --version\n",
    "!{mongorestore} --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68245d2b",
   "metadata": {},
   "source": [
    "### Create MongoDB clients\n",
    "\n",
    "Create MongoDB clients you can use to access the \"origin\" and \"transformer\" MongoDB servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mongo client for \"origin\" MongoDB server.\n",
    "origin_mongo_client = pymongo.MongoClient(host=cfg.origin_mongo_server_uri, directConnection=True)\n",
    "\n",
    "# Mongo client for \"transformer\" MongoDB server.\n",
    "transformer_mongo_client = pymongo.MongoClient(host=cfg.transformer_mongo_server_uri)\n",
    "\n",
    "# Perform sanity tests of those MongoDB clients' abilities to access their respective MongoDB servers.\n",
    "with pymongo.timeout(3):\n",
    "    # Display the MongoDB server version (running on the \"origin\" Mongo server).\n",
    "    print(\"Origin Mongo server version:      \" + origin_mongo_client.server_info()[\"version\"])\n",
    "\n",
    "    # Sanity test: Ensure the origin database exists.\n",
    "    assert \"nmdc\" in origin_mongo_client.list_database_names(), \"Origin database does not exist.\"\n",
    "\n",
    "    # Display the MongoDB server version (running on the \"transformer\" Mongo server).\n",
    "    print(\"Transformer Mongo server version: \" + transformer_mongo_client.server_info()[\"version\"])\n",
    "\n",
    "    # Sanity test: Ensure the transformation database does not exist.\n",
    "    assert \"nmdc\" not in transformer_mongo_client.list_database_names(), \"Transformation database already exists.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc387abc62686091",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Create a bookkeeper\n",
    "\n",
    "Create a `Bookkeeper` that can be used to document migration events in the \"origin\" server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c982eb0c04e606d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bookkeeper = Bookkeeper(mongo_client=origin_mongo_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3975ac24",
   "metadata": {},
   "source": [
    "### Create JSON Schema validator\n",
    "\n",
    "In this step, you'll create a JSON Schema validator for the NMDC Schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2dbb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_id_pattern_constraints(nmdc_schema: dict) -> dict:\n",
    "    r\"\"\"\n",
    "    Returns a variant of the schema having no `$defs[*].properties.id.pattern` properties.\n",
    "\n",
    "    Note: This algorithm was copied from the `without_id_patterns` function in `nmdc_runtime/util.py`.\n",
    "    \"\"\"\n",
    "    custom_schema = deepcopy(nmdc_schema)\n",
    "    for spec in custom_schema[\"$defs\"].values():\n",
    "        if \"properties\" in spec and \"id\" in spec[\"properties\"] and \"pattern\" in spec[\"properties\"][\"id\"]:\n",
    "            del spec[\"properties\"][\"id\"][\"pattern\"]\n",
    "    return custom_schema\n",
    "\n",
    "\n",
    "# Make a version of the NMDC Schema that accepts so-called \"legacy IDs\".\n",
    "nmdc_jsonschema: dict = remove_id_pattern_constraints(get_nmdc_jsonschema_dict())\n",
    "nmdc_jsonschema_validator = Draft7Validator(nmdc_jsonschema)\n",
    "\n",
    "# Perform sanity tests of the NMDC Schema dictionary and the JSON Schema validator.\n",
    "# Reference: https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/protocols/#jsonschema.protocols.Validator.check_schema\n",
    "print(\"NMDC Schema title:   \" + nmdc_jsonschema[\"title\"])\n",
    "print(\"NMDC Schema version: \" + nmdc_jsonschema[\"version\"])\n",
    "\n",
    "nmdc_jsonschema_validator.check_schema(nmdc_jsonschema)  # raises exception if schema is invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4994a0",
   "metadata": {},
   "source": [
    "### Dump collections from the \"origin\" MongoDB server\n",
    "\n",
    "Use `mongodump` to dump the collections involved in this migration **from** the \"origin\" MongoDB server **into** a local directory.\n",
    "\n",
    "> Since `mongodump` doesn't provide a CLI option we can use to specify the collections we _want_ the dump to include, we use multiple occurrences of the `--excludeCollection` CLI option to exclude each collection we do _not_ want the dump to include. The end result is the same—there's just that extra step involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8fa1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a string containing zero or more `--excludeCollection=\"...\"` options, which can be included in a `mongodump` command.\n",
    "all_collection_names: list[str] = origin_mongo_client[\"nmdc\"].list_collection_names()\n",
    "non_agenda_collection_names = [name for name in all_collection_names if name not in COLLECTION_NAMES]\n",
    "exclusion_options = [f\"--excludeCollection='{name}'\" for name in non_agenda_collection_names]\n",
    "exclusion_options_str = \" \".join(exclusion_options)  # separates each option with a space\n",
    "print(exclusion_options_str)\n",
    "\n",
    "# Dump the not-excluded collections from the \"origin\" database.\n",
    "!{mongodump} \\\n",
    "  --config=\"{cfg.origin_mongo_config_file_path}\" \\\n",
    "  --db=\"nmdc\" \\\n",
    "  --gzip \\\n",
    "  --out=\"{cfg.origin_dump_folder_path}\" \\\n",
    "  {exclusion_options_str}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e3c9c4",
   "metadata": {},
   "source": [
    "### Load the dumped collections into the \"transformer\" MongoDB server\n",
    "\n",
    "Use `mongorestore` to load the dumped collections **from** the local directory **into** the \"transformer\" MongoDB server.\n",
    "\n",
    "> Since it's possible that the dump included extra collections (due to someone having created a collection between the time you generated the `--excludeCollection` CLI options and the time you ran `mongodump` above), we will use the `--nsInclude` CLI option to indicate which specific collections—from the dump—we want to load into the \"transformer\" database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418571c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a string containing zero or more `--nsInclude=\"...\"` options, which can be included in a `mongorestore` command.\n",
    "inclusion_options = [f\"--nsInclude='nmdc.{name}'\" for name in COLLECTION_NAMES]\n",
    "inclusion_options_str = \" \".join(inclusion_options)  # separates each option with a space\n",
    "print(inclusion_options_str)\n",
    "\n",
    "# Restore the dumped collections to the \"transformer\" MongoDB server.\n",
    "!{mongorestore} \\\n",
    "  --config=\"{cfg.transformer_mongo_config_file_path}\" \\\n",
    "  --gzip \\\n",
    "  --drop \\\n",
    "  --preserveUUID \\\n",
    "  --dir=\"{cfg.origin_dump_folder_path}\" \\\n",
    "  {inclusion_options_str}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c090068",
   "metadata": {},
   "source": [
    "### Transform the collections within the \"transformer\" MongoDB server\n",
    "\n",
    "Use the migrator to transform the collections in the \"transformer\" database.\n",
    "\n",
    "> Reminder: The database transformation functions are defined in the `nmdc-schema` Python package installed earlier.\n",
    "\n",
    "> Reminder: The \"origin\" database is **not** affected by this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05869340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a MongoAdapter bound to the \"transformer\" database.\n",
    "adapter = MongoAdapter(\n",
    "    database=transformer_mongo_client[\"nmdc\"],\n",
    "    # Note: These callbacks aren't support yet, as of nmdc-schema 10.1.4.\n",
    "    # on_collection_created=lambda name: print(f'Created collection \"{name}\"'),\n",
    "    # on_collection_renamed=lambda old_name, name: print(f'Renamed collection \"{old_name}\" to \"{name}\"'),\n",
    "    # on_collection_deleted=lambda name: print(f'Deleted collection \"{name}\"'),\n",
    ")\n",
    "\n",
    "# Instantiate a Migrator bound to that adapter.\n",
    "migrator = Migrator(adapter=adapter)\n",
    "\n",
    "# Execute the Migrator's `upgrade` method to perform the migration.\n",
    "migrator.upgrade()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edf77c7",
   "metadata": {},
   "source": [
    "### Validate the transformed documents\n",
    "\n",
    "Now that we have transformed the database, validate each document in each collection in the \"transformer\" MongoDB server.\n",
    "\n",
    "> Reference: https://github.com/microbiomedata/nmdc-runtime/blob/main/metadata-translation/src/bin/validate_json.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for collection_name in COLLECTION_NAMES:\n",
    "    collection = transformer_mongo_client[\"nmdc\"][collection_name]\n",
    "    for document in collection.find():\n",
    "        # Validate the transformed document.\n",
    "        #\n",
    "        # Reference: https://github.com/microbiomedata/nmdc-schema/blob/main/src/docs/schema-validation.md\n",
    "        #\n",
    "        # Note: Dictionaries originating as Mongo documents include a Mongo-generated key named `_id`. However,\n",
    "        #       the NMDC Schema does not describe that key and, indeed, data validators consider dictionaries\n",
    "        #       containing that key to be invalid with respect to the NMDC Schema. So, here, we validate a\n",
    "        #       copy (i.e. a shallow copy) of the document that lacks that specific key.\n",
    "        #\n",
    "        # Note: `root_to_validate` is a dictionary having the shape: { \"some_collection_name\": [ some_document ] }\n",
    "        #       Reference: https://docs.python.org/3/library/stdtypes.html#dict (see the \"type constructor\" section)\n",
    "        #\n",
    "        document_without_underscore_id_key = {key: value for key, value in document.items() if key != \"_id\"}\n",
    "        root_to_validate = dict([(collection_name, [document_without_underscore_id_key])])\n",
    "        try:\n",
    "            nmdc_jsonschema_validator.validate(root_to_validate)  # raises exception if invalid\n",
    "        except ValidationError as err:\n",
    "            # Print the offending document (to facilitate debug) before propagating the exception.\n",
    "            print(document)\n",
    "            raise err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997fcb281d9d3222",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Indicate that the migration is underway\n",
    "\n",
    "Add an entry to the migration log collection to indicate that this migration has started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcafd862e1becb98",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bookkeeper.record_migration_event(migrator=migrator, event=MigrationEvent.MIGRATION_STARTED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0c8891",
   "metadata": {},
   "source": [
    "### Dump the collections from the \"transformer\" MongoDB server\n",
    "\n",
    "Now that the collections have been transformed and validated, dump them **from** the \"transformer\" MongoDB server **into** a local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca49f61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the database from the \"transformer\" MongoDB server.\n",
    "!{mongodump} \\\n",
    "  --config=\"{cfg.transformer_mongo_config_file_path}\" \\\n",
    "  --db=\"nmdc\" \\\n",
    "  --gzip \\\n",
    "  --out=\"{cfg.transformer_dump_folder_path}\" \\\n",
    "  {exclusion_options_str}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84bdc11",
   "metadata": {},
   "source": [
    "### Load the collections into the \"origin\" MongoDB server\n",
    "\n",
    "Load the transformed collections into the \"origin\" MongoDB server, **replacing** the collections there that have the same names.\n",
    "\n",
    "> Note: If the migration involved renaming or deleting a collection, the collection having the original name will continue to exist in the \"origin\" database until someone deletes it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfbcf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the same-named collection(s) on the origin server, with the transformed one(s).\n",
    "!{mongorestore} \\\n",
    "  --config=\"{cfg.origin_mongo_config_file_path}\" \\\n",
    "  --gzip \\\n",
    "  --verbose \\\n",
    "  --dir=\"{cfg.transformer_dump_folder_path}\" \\\n",
    "  --drop \\\n",
    "  --preserveUUID \\\n",
    "  {inclusion_options_str}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5ee89a79148499",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Indicate that the migration is complete\n",
    "\n",
    "Add an entry to the migration log collection to indicate that this migration is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eaa6c92789c4f3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bookkeeper.record_migration_event(migrator=migrator, event=MigrationEvent.MIGRATION_COMPLETED)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
