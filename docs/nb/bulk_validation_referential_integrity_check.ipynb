{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a66b2dc",
   "metadata": {},
   "source": [
    "# Referential integrity checker (prototype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c892eac06fb1a86a",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, make sure you have done the following:\n",
    "\n",
    "1. Run `$ make up-dev`\n",
    "2. Map `localhost:27018` to the Mongo server you want to use\n",
    "3. Load a recent dump of the production Mongo database into that Mongo server (see `$ make mongorestore-nmdc-db` for an example)\n",
    "4. In the `.env` file, set `MONGO_HOST` to `mongodb://localhost:27018`\n",
    "5. Run `$ export $(grep -v '^#' .env | xargs)` to load the environment variables defined in `.env` into your shell environment\n",
    "6. Run `make init` to ensure a consistent python kernel for this notebook.\n",
    "\n",
    "Once you've done all of those things, you can run this notebook (e.g. via `$ jupyter notebook`) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e58d1c-0d88-4830-b618-0bd8de703215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mongodb://localhost:27018\n"
     ]
    }
   ],
   "source": [
    "!echo $MONGO_HOST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f03ce22",
   "metadata": {},
   "source": [
    "## Enable automatic reloading of modules\n",
    "\n",
    "Reference: https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html#autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c8bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure code changes in this notebook will be import-able  \n",
    "# without needing to restart the kernel and lose state\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5121e612",
   "metadata": {},
   "source": [
    "## Import Python modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edb8bf0-cd9d-47da-a33d-081d352fbaec",
   "metadata": {},
   "source": [
    "Be sure you're using the version of `nmdc-schema` you think you are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f62482-2b3e-469a-b262-1e8743e1a106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.0.0rc22'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "version(\"nmdc-schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ff0664-1881-4eca-b018-4c5856dc2489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import concurrent.futures\n",
    "from itertools import chain\n",
    "import os\n",
    "import re\n",
    "\n",
    "from linkml_runtime.utils.schemaview import SchemaView\n",
    "from pymongo import InsertOne\n",
    "from toolz import dissoc, assoc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from nmdc_runtime.api.core.util import pick\n",
    "from nmdc_runtime.api.db.mongo import get_mongo_db, get_nonempty_nmdc_schema_collection_names, get_collection_names_from_schema\n",
    "from nmdc_runtime.util import collection_name_to_class_names, populated_schema_collection_names_with_id_field, nmdc_schema_view, nmdc_database_collection_instance_class_names, get_nmdc_jsonschema_dict\n",
    "from nmdc_schema.nmdc import Database as NMDCDatabase \n",
    "from nmdc_schema.get_nmdc_view import ViewGetter\n",
    "\n",
    "mdb = get_mongo_db()\n",
    "schema_view = nmdc_schema_view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb5802b-8205-49b7-8784-dc137baff1a0",
   "metadata": {},
   "source": [
    "## Check for errors in the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab96cda-30ab-4e93-a0b1-3a936599305d",
   "metadata": {},
   "source": [
    "The `nmdc_schema_collection_names` function returns the populated (having at least one document) set-intersection of (a) the set of collection names present in the Mongo database and (b) the set of Database slots in the schema that correspond to a collection (defined as being multivalued and values being inlined as a list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d76b70e-4412-4b17-9db9-322ac791859a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'study_set', 'workflow_execution_set', 'material_processing_set', 'instrument_set', 'data_object_set', 'configuration_set', 'biosample_set', 'functional_annotation_agg', 'calibration_set', 'processed_sample_set', 'field_research_site_set', 'data_generation_set'}\n"
     ]
    }
   ],
   "source": [
    "collection_names = get_nonempty_nmdc_schema_collection_names(mdb)\n",
    "print(collection_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f058e8d7-7d5f-4c8d-8136-eb808eba88bc",
   "metadata": {},
   "source": [
    "Collect all possible classes of documents across all schema collections. `collection_name_to_class_names` is a mapping from collection name to a list of class names allowable for that collection's documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df817f5c-77bf-48eb-a77a-432fa1b01052",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_class_names = set(chain.from_iterable(collection_name_to_class_names.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab85fd8-8b84-49ca-af26-cd9f4b4b8cb4",
   "metadata": {},
   "source": [
    "Map each document-class name to a map of slot name to slot definition. Class slots here are (to quote the LinkML SchemaView documentation) \"all slots that are asserted or inferred for [the] class, with their inferred semantics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b63a22ec-33ce-4e69-84cb-cf9837f932e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_slot_map = {\n",
    "    cls_name : {slot.name: slot\n",
    "                for slot in schema_view.class_induced_slots(cls_name)\n",
    "               }\n",
    "    for cls_name in document_class_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e7d00e-0ec4-45de-b0da-1b618ef7e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_errors(note_doc_field_errors):\n",
    "    errors = {\"bad_type\": [], \"no_type\": [], \"bad_slot\": [], \"is_null\": []}\n",
    "    n_docs_total = sum(mdb[coll_name].estimated_document_count() for coll_name in collection_names)\n",
    "    pbar = tqdm(total=n_docs_total)\n",
    "    n_errors_cache = 0\n",
    "    for coll_name in sorted(collection_names):\n",
    "        cls_names = collection_name_to_class_names[coll_name]\n",
    "        pbar.set_description(f\"processing {coll_name}...\")\n",
    "        # Iterate over each document (as a dictionary) in this collection.\n",
    "        for doc in mdb[coll_name].find():\n",
    "            doc = dissoc(doc, \"_id\")\n",
    "            \n",
    "            # Ensure we know the document's type.\n",
    "            cls_name = None\n",
    "            cls_type_match = re.match(r\"^nmdc:(?P<name>.+)\", doc.get(\"type\", \"\"))\n",
    "            if cls_type_match is not None:\n",
    "                cls_name = cls_type_match.group(\"name\")\n",
    "                if cls_name not in cls_names:\n",
    "                    errors[\"bad_type\"].append(f\"{coll_name} doc {doc['id']}: doc type {cls_name} not in those allowed for {coll_name}, i.e. {cls_names}.\")\n",
    "                    cls_name = None\n",
    "            elif len(cls_names) == 1:\n",
    "                cls_name = cls_names[0]\n",
    "            else:\n",
    "                errors[\"no_type\"].append(f\"{coll_name} doc {doc['id']}: 'type' not set.\")\n",
    "\n",
    "            if cls_name is not None:        \n",
    "                slot_map = cls_slot_map[cls_name]\n",
    "                # Iterate over each key/value pair in the dictionary (document).\n",
    "                for field, value in doc.items():\n",
    "                    if field in slot_map:\n",
    "                        if not isinstance(value, list):\n",
    "                            value = [value]\n",
    "                        for v in value:\n",
    "                            note_doc_field_errors(value=v,field=field,doc=doc,coll_name=coll_name,errors=errors)                \n",
    "                    else:\n",
    "                        errors[\"bad_slot\"].append(f\"{coll_name} doc {doc['id']}: field '{field}' not a valid slot\")\n",
    "            pbar.update(1)\n",
    "            n_errors = sum([len(v) for v in errors.values()])\n",
    "            if n_errors > n_errors_cache:\n",
    "                print(f\"{n_errors} errors so far...\")\n",
    "                n_errors_cache = n_errors\n",
    "    pbar.close()\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14afb4c6-b0b7-4fd7-8e2f-13c682c74409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_doc_field_errors(value=None, field=None, doc=None, coll_name=None, errors=None):\n",
    "    # No fields should be null-valued.\n",
    "    # Example of how this may happen: JSON serialization from pydantic models may set optional fields to `null`.\n",
    "    if value is None:\n",
    "        errors[\"is_null\"].append(f\"{coll_name} doc {doc['id']}: field {field} is null.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "829039e5-7abe-4c50-ba44-e384b45b7535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c88577a3a9342808d3bbc0e3707a95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2351449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bad_type': [], 'no_type': [], 'bad_slot': [], 'is_null': []}\n"
     ]
    }
   ],
   "source": [
    "errors = collect_errors(note_doc_field_errors)\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2f771-b8da-466a-90e8-2c17ac5e6388",
   "metadata": {},
   "source": [
    "## Materialize single-collection view of database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b962e3c8-a346-49c5-8470-915f3cf9eb07",
   "metadata": {},
   "source": [
    "The `alldocs` collection associates each database document's `id` with not only its class (via that document's `type` field) but also with all ancestors of the docuement's class.\n",
    "\n",
    "The set-of-classes association is done by setting the `type` field in an `alldocs` document to be a list, which facilitates filtering by type using the same strutured query forms as for upstream schema collections. The first element of the `type` list *must* correspond to the source document's asserted class; this is so that validation code can determine the expected range of document slots, as slot ranges may be specialized by a class (via linkml \"slot_usage\").\n",
    "\n",
    "To keep the `alldocs` collection focused on supporting referential-integrity checking, only document-reference-ranged slots from source documents are copied to an entity's corresponding `alldocs` materialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98fbfdff-51d6-42c5-9448-3b4616a2c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any ancestor of a document class is a document-referenceable range, i.e., a valid range of a document-reference-ranged slot.\n",
    "document_referenceable_ranges = set(chain.from_iterable(schema_view.class_ancestors(cls_name) for cls_name in document_class_names))\n",
    "\n",
    "document_reference_ranged_slots = defaultdict(list)\n",
    "for cls_name, slot_map in cls_slot_map.items():\n",
    "    for slot_name, slot in slot_map.items():\n",
    "        if str(slot.range) in document_referenceable_ranges:\n",
    "            document_reference_ranged_slots[cls_name].append(slot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d253c567-533f-440f-8376-03a6e1e905cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_cls(doc, coll_name=None):\n",
    "    \"\"\"Return unprefixed name of document class.\n",
    "\n",
    "    Try to get from doc['type'] (lopping off 'nmdc:' prefix).\n",
    "    Else, if can unambiguously infer type given coll_name, use that.\n",
    "    Else, return None.\n",
    "    \"\"\"\n",
    "    if 'type' in doc:\n",
    "        return doc['type'][5:] # lop off \"nmdc:\" prefix\n",
    "    elif coll_name and len(collection_name_to_class_names[coll_name]) == 1:\n",
    "        return collection_name_to_class_names[coll_name][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2e618f3-78b9-42b6-8ea9-63d080b1b0f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63a4ce942bc4278b3e99a5a87b0155c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2351449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refreshed `alldocs` collection\n"
     ]
    }
   ],
   "source": [
    "# Drop any existing `alldocs` collection (e.g. from previous use of this notebook).\n",
    "mdb.alldocs.drop()\n",
    "\n",
    "# Set up progress bar\n",
    "n_docs_total = sum(mdb[name].estimated_document_count() for name in collection_names)\n",
    "pbar = tqdm(total=n_docs_total)\n",
    "\n",
    "for coll_name in collection_names:\n",
    "    pbar.set_description(f\"processing {coll_name}...\")\n",
    "    requests = []\n",
    "    for doc in mdb[coll_name].find():\n",
    "        doc_type = doc_cls(doc, coll_name=coll_name)\n",
    "        slots_to_include = [\"id\"] + document_reference_ranged_slots[doc_type]\n",
    "        new_doc = pick(slots_to_include, doc)\n",
    "        new_doc[\"type\"] = schema_view.class_ancestors(doc_type)\n",
    "        requests.append(InsertOne(new_doc))\n",
    "        if len(requests) == 1000: # ensure bulk-write batches aren't too huge\n",
    "            result = mdb.alldocs.bulk_write(requests, ordered=False)\n",
    "            pbar.update(result.inserted_count)\n",
    "            requests.clear()\n",
    "    if len(requests) > 0:\n",
    "        result = mdb.alldocs.bulk_write(requests, ordered=False)\n",
    "        pbar.update(result.inserted_count)\n",
    "pbar.close()\n",
    "\n",
    "# Prior to re-ID-ing, some IDs are not unique across Mongo collections (eg nmdc:0078a0f981ad3f92693c2bc3b6470791)\n",
    "\n",
    "# Ensure unique id index for `alldocs` collection.\n",
    "# The index is sparse because e.g. nmdc:FunctionalAnnotationAggMember documents don't have an \"id\".\n",
    "mdb.alldocs.create_index(\"id\", unique=True, sparse=True)\n",
    "\n",
    "print(\"refreshed `alldocs` collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0569fde",
   "metadata": {},
   "source": [
    "The resulting `alldocs` collection contains a copy of every document from every Mongo collection identified earlier. The copy has a subset of the key-value pairs as the original document, except that its `type` field contains a list of the names of its own class and all of its ancestor classes (whereas the original document's `type` field either is unset or contains its own class only)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca194c0f-7417-41d2-bea8-a5a54392fee6",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645690e-7a9d-4f1e-8e62-0cbdde825890",
   "metadata": {},
   "source": [
    "### Check referential integrity\n",
    "\n",
    "In this cell, we populate two lists:\n",
    "\n",
    "- `errors.not_found`: a list of \"naive\" errors\n",
    "- `errors.invalid_type`: a list of (hierarchy-aware) type errors (document was found, but is of an invalid type)\n",
    "\n",
    "Reference: https://linkml.io/linkml/developers/schemaview.html#linkml_runtime.utils.schemaview.SchemaView.class_induced_slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0374653-c074-4a87-aef8-24323a5a63b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_assertions(limit=0):\n",
    "    \"\"\"Yields batches of 1000 assertions to greatly speed up processing.\"\"\"\n",
    "    # Initialize progress bar.\n",
    "    pbar = tqdm(total=(mdb.alldocs.estimated_document_count() if limit == 0 else limit))\n",
    "    rv = []\n",
    "    for doc in mdb.alldocs.find(limit=limit):\n",
    "        # Iterate over each key/value pair in the dictionary (document).\n",
    "        for field, value in doc.items():\n",
    "            if field in (\"_id\", \"id\", \"type\"):\n",
    "                continue\n",
    "            slot_range = str(cls_slot_map[doc[\"type\"][0]][field].range) # assumes upstream doc type is listed first.\n",
    "            if not isinstance(value, list):\n",
    "                value = [value]\n",
    "            for v in value:\n",
    "                rv.append({\n",
    "                    \"id\": doc.get(\"id\", doc[\"_id\"]),\n",
    "                    \"id_is_nmdc_id\": \"id\" in doc,\n",
    "                    \"field\": field,\n",
    "                    \"value\": v,\n",
    "                    \"slot_range\": slot_range,\n",
    "                })\n",
    "                if len(rv) == 1000:\n",
    "                    yield rv\n",
    "                    rv.clear()\n",
    "        pbar.update(1)\n",
    "    yield rv\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "103d70b6-24ab-41bd-8b7f-d2faaa028bdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c75b6bd622470f9ded8e3813fc1d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3039449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def doc_field_value_errors(assertions):\n",
    "    errors = {\"not_found\": [], \"invalid_type\": []}\n",
    "    assertions_by_referenced_id_value = defaultdict(list)\n",
    "    for a in assertions:\n",
    "        assertions_by_referenced_id_value[a[\"value\"]].append(a)\n",
    "    doc_id_types = {}\n",
    "    for d in list(mdb.alldocs.find({\"id\": {\"$in\": list(assertions_by_referenced_id_value.keys())}}, {\"_id\": 0, \"id\": 1, \"type\": 1})):\n",
    "        doc_id_types[d[\"id\"]] = d[\"type\"]\n",
    "\n",
    "    for id_value, id_value_assertions in assertions_by_referenced_id_value.items():\n",
    "        if id_value not in doc_id_types:\n",
    "            errors[\"not_found\"].extend(id_value_assertions)\n",
    "        else:\n",
    "            for a in id_value_assertions:\n",
    "                if a[\"slot_range\"] not in doc_id_types[a[\"value\"]]:\n",
    "                    errors[\"invalid_type\"].append(a)\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "# Initialize \"global\" error lists.\n",
    "errors = {\"not_found\": [], \"invalid_type\": []}\n",
    "\n",
    "# Use a with statement to ensure threads are cleaned up promptly\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=None) as executor:\n",
    "    future_to_errors = {executor.submit(doc_field_value_errors, das): das for das in doc_assertions()}\n",
    "    for future in concurrent.futures.as_completed(future_to_errors):\n",
    "        doc_asserts = future_to_errors[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print(\"exception:\", str(exc))\n",
    "        else:\n",
    "            errors[\"not_found\"].extend(data[\"not_found\"])\n",
    "            errors[\"invalid_type\"].extend(data[\"invalid_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2ce4a3-fb33-4b47-9c7f-a7919405ab65",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Display the number errors in each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e01450d1-3369-4fc5-80be-9787e00a6597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 45604)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors[\"not_found\"]), len(errors[\"invalid_type\"])\n",
    "# results prior to re-id-ing: (4857, 23503)\n",
    "# results prior to v10.5.5: (33, 20488)\n",
    "# results with v10.5.5: (33, 6900)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a560df",
   "metadata": {},
   "source": [
    "Display a few errors from one of the lists, as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afd25543-1cb3-4887-9aba-0086d4b998a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nmdc:dobj-11-cvcxxr53', 'nmdc:dobj-11-fg28a080', 'nmdc:dobj-11-gxgpbv06'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{e[\"value\"] for e in errors[\"not_found\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a25857f4-e26e-4896-9e5f-607e7b4bb07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'nmdc:wfmgan-11-w1d6gy98.1',\n",
       "  'id_is_nmdc_id': True,\n",
       "  'field': 'has_input',\n",
       "  'value': 'nmdc:dobj-11-cvcxxr53',\n",
       "  'slot_range': 'NamedThing'},\n",
       " {'id': 'nmdc:wfmgan-11-fmymf551.1',\n",
       "  'id_is_nmdc_id': True,\n",
       "  'field': 'has_input',\n",
       "  'value': 'nmdc:dobj-11-fg28a080',\n",
       "  'slot_range': 'NamedThing'},\n",
       " {'id': 'nmdc:wfmgan-11-3nkefn97.1',\n",
       "  'id_is_nmdc_id': True,\n",
       "  'field': 'has_input',\n",
       "  'value': 'nmdc:dobj-11-gxgpbv06',\n",
       "  'slot_range': 'NamedThing'},\n",
       " {'id': 'nmdc:wfmgan-11-fmymf551.1',\n",
       "  'id_is_nmdc_id': True,\n",
       "  'field': 'has_input',\n",
       "  'value': 'nmdc:dobj-11-fg28a080',\n",
       "  'slot_range': 'NamedThing'},\n",
       " {'id': 'nmdc:wfmgan-11-3nkefn97.1',\n",
       "  'id_is_nmdc_id': True,\n",
       "  'field': 'has_input',\n",
       "  'value': 'nmdc:dobj-11-gxgpbv06',\n",
       "  'slot_range': 'NamedThing'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors[\"not_found\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd191cd",
   "metadata": {},
   "source": [
    "Display an example `invalid_type` errors for each of the set of expected types that are not being found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33516e3c-f10d-4c30-942b-0d01d06082f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'nmdc:dobj-11-xt088e26', 'id_is_nmdc_id': True, 'field': 'was_generated_by', 'value': 'nmdc:omprc-11-ymxzx274', 'slot_range': 'WorkflowExecution'}\n"
     ]
    }
   ],
   "source": [
    "slot_range_examples = {}\n",
    "for e in errors[\"invalid_type\"]:\n",
    "    slot_range_examples[e[\"slot_range\"]] = e\n",
    "\n",
    "for ex in slot_range_examples.values():\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4abec53",
   "metadata": {},
   "source": [
    "Spot check one of those errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29ec7e82-d079-4525-bd7b-d770fd69d788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('66edad78007ef07eb670a09d'),\n",
       " 'id': 'nmdc:omprc-11-sxze4w22',\n",
       " 'has_input': ['nmdc:bsm-11-978cs285'],\n",
       " 'has_output': ['nmdc:dobj-11-1epz0d53'],\n",
       " 'associated_studies': ['nmdc:sty-11-28tm5d36'],\n",
       " 'instrument_used': ['nmdc:inst-14-mwrrj632'],\n",
       " 'type': ['MassSpectrometry',\n",
       "  'DataGeneration',\n",
       "  'PlannedProcess',\n",
       "  'NamedThing']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OmicsProcessing is not subclass of Activity\n",
    "mdb.alldocs.find_one({\"id\": \"nmdc:omprc-11-sxze4w22\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "802290e0-58dd-4fbd-835a-c9928006819d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('66edad78007ef07eb67078c8'),\n",
       " 'id': 'nmdc:procsm-11-v5sykd35',\n",
       " 'type': ['ProcessedSample', 'MaterialEntity', 'NamedThing']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ProcessedSample is not subclass of Biosample\n",
    "mdb.alldocs.find_one({\"id\": \"nmdc:procsm-11-v5sykd35\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
