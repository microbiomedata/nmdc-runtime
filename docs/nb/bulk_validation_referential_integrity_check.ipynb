{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a66b2dc",
   "metadata": {},
   "source": [
    "# Referential integrity checker (prototype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c892eac06fb1a86a",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, make sure you have done the following:\n",
    "\n",
    "1. Run `$ make up-dev`\n",
    "2. Map `localhost:27018` to the Mongo server you want to use\n",
    "3. Load a recent dump of the production Mongo database into that Mongo server (see `$ make mongorestore-nmdc-dev` for an example)\n",
    "4. In the `.env` file, set `MONGO_HOST` to `mongodb://localhost:27018`\n",
    "5. Run `$ export $(grep -v '^#' .env | xargs)` to load the environment variables defined in `.env` into your shell environment\n",
    "\n",
    "Once you've done all of those things, you can run this notebook (e.g. via `$ jupyter notebook`) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f03ce22",
   "metadata": {},
   "source": [
    "## Enable automatic reloading of modules\n",
    "\n",
    "Reference: https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html#autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1c8bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure code changes in this notebook will be import-able  \n",
    "# without needing to restart the kernel and lose state\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5121e612",
   "metadata": {},
   "source": [
    "## Import Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7ff0664-1881-4eca-b018-4c5856dc2489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from linkml_runtime.utils.schemaview import SchemaView\n",
    "from toolz import dissoc, assoc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from nmdc_runtime.api.db.mongo import get_mongo_db, nmdc_schema_collection_names\n",
    "from nmdc_runtime.util import collection_name_to_class_names, nmdc_schema_view, nmdc_database_collection_instance_class_names\n",
    "from nmdc_schema.nmdc import Database as NMDCDatabase\n",
    "from nmdc_schema.get_nmdc_view import ViewGetter\n",
    "\n",
    "mdb = get_mongo_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb5802b-8205-49b7-8784-dc137baff1a0",
   "metadata": {},
   "source": [
    "## \"Pre-clean\" the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecb1950-eaec-469c-b7ac-949650825093",
   "metadata": {},
   "source": [
    "Determine the name of each Mongo collection in which at least one document has a field named `id`.\n",
    "\n",
    "> **TODO:** Documents in the [`functional_annotation_agg` collection](https://microbiomedata.github.io/nmdc-schema/FunctionalAnnotationAggMember/) do not have a field named `id`, and so will not be included here. Document the author's rationale for omitting it.\n",
    "\n",
    "> **TODO:** The `nmdc_schema_collection_names` function combines the collection names in Mongo with the Database slots in the schema, and then omits some collection names. Document why the author took that approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dde4c77e-5e06-4751-930a-95906cdf89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_names = sorted(nmdc_schema_collection_names(mdb))\n",
    "collection_names = [n for n in collection_names if mdb[n].find_one({\"id\": {\"$exists\": True}})]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddaaa54-262d-4549-a9a9-4c280a6a6341",
   "metadata": {},
   "source": [
    "### Remove fields that contain null\n",
    "\n",
    "Remove specific fields from specific documents in the above collections, if the field's name appears in our hard-coded list (see the cell below for the list) and — in that document — the field consists of a null value.\n",
    "\n",
    "> **TODO:** Document how the author obtained this list and whether the list would require maintenance over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b71ba7d2-ebd2-487d-a5cc-2a85ee14cb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479e8019dd6a4206bd684eff67ae29d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing 1119 null-valued used values for read_qc_analysis_activity_set...\n"
     ]
    }
   ],
   "source": [
    "# check these slots for null values for all docs in collection_names\n",
    "props = [\"used\", \"git_url\", \"was_associated_with\", \"was_generated_by\", \"compression_type\", \n",
    "         \"metagenome_annotation_id\", \"metaproteomic_analysis_id\"] \n",
    "\n",
    "pbar = tqdm(total=len(collection_names))\n",
    "for p in props:\n",
    "    for coll_name in collection_names:\n",
    "        pbar.set_description(f\"checking {coll_name}...\")\n",
    "        # The {$type: 10} query matches for BSON Type Null, not just value `null`\n",
    "        docs_broken = list(mdb[coll_name].find({p: {\"$type\": 10}}, [\"id\"]))\n",
    "        if docs_broken:\n",
    "            print(f\"removing {len(docs_broken)} null-valued {p} values for {coll_name}...\")\n",
    "            mdb[coll_name].update_many(\n",
    "                {\"id\": {\"$in\": [d[\"id\"] for d in docs_broken]}},\n",
    "                {\"$unset\": {p: None}}\n",
    "            )\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2f771-b8da-466a-90e8-2c17ac5e6388",
   "metadata": {},
   "source": [
    "## Materialize single-collection view of database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d6c224-ec80-4ac9-9dcf-bf04b33a61f9",
   "metadata": {},
   "source": [
    "Check assumption that every populated collection currently has documents of one type only.\n",
    "\n",
    "> **TODO:** The \"class_names\" part of the `collection_name_to_class_names` dictionary does not list _descendant_ classes, even though the schema will allow instances of descendant classes to reside in those collections. Document why disregarding descendant classes here is OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59176b24-2854-4387-891f-a6be2ceca4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in collection_names:\n",
    "    assert len(collection_name_to_class_names[name]) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed95ee0-03b7-4dff-80e7-92a2b24bccf4",
   "metadata": {},
   "source": [
    "Define a helper function that takes a class instance and returns a list of the names of its own class and its ancestor classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4470c52a-81e4-4511-b549-768c04c3b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_hierarchy_as_list(obj) -> list[str]:\n",
    "    r\"\"\"\n",
    "    Returns a list consisting of the name of the class of the instance pass in,\n",
    "    and the names of all of its ancestor classes.\n",
    "\n",
    "    TODO: Consider renaming function to be a verb; e.g. `get_class_hierarchy_as_list`.\n",
    "\n",
    "    TODO: Document the purpose of the `rv` list (does not seem to be used anywhere).\n",
    "    \"\"\"\n",
    "\n",
    "    rv = []\n",
    "    current_class = obj.__class__\n",
    "    \n",
    "    def recurse_through_bases(cls):\n",
    "        name = cls.__name__\n",
    "        if name == \"YAMLRoot\":  # base case\n",
    "            return rv\n",
    "        rv.append(name)\n",
    "        for base in cls.__bases__:\n",
    "            recurse_through_bases(base)  # recursive invocation\n",
    "        return rv\n",
    "    \n",
    "    return recurse_through_bases(current_class)  # initial invocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b962e3c8-a346-49c5-8470-915f3cf9eb07",
   "metadata": {},
   "source": [
    "Materialize `alldocs` collection, associating all inherited classes with document via `type` field.\n",
    "\n",
    "> **TODO:** Clarify the above sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2e618f3-78b9-42b6-8ea9-63d080b1b0f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41680085d444a8abd087171819b0d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150019 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refreshed `alldocs` collection\n"
     ]
    }
   ],
   "source": [
    "# Drop any existing `alldocs` collection (e.g. from previous use of this notebook).\n",
    "mdb.alldocs.drop()\n",
    "\n",
    "# Set up progress bar\n",
    "n_docs_total = sum(mdb[name].estimated_document_count() for name in collection_names)\n",
    "pbar = tqdm(total=n_docs_total)\n",
    "\n",
    "# for each collection name make sure it's populated\n",
    "for coll_name in collection_names:\n",
    "    pbar.set_description(f\"processing {coll_name}...\")\n",
    "    try:\n",
    "        nmdcdb = NMDCDatabase(**{coll_name: [dissoc(mdb[coll_name].find_one(), '_id')]})\n",
    "    except ValueError as e:\n",
    "        print(f\"no {coll_name}!\")\n",
    "        raise e\n",
    "\n",
    "    # Calculate class_hierarchy_as_list once per collection.\n",
    "    #\n",
    "    # Note: This seems to assume that the class hierarchy is identical for each document\n",
    "    #       in a given collection, which may not be the case since a collection whose\n",
    "    #       range is a \"parent\" class can store instances of descendant classes (and the\n",
    "    #       class hierarchy of the latter would differ from that of the former).\n",
    "    #\n",
    "    exemplar = getattr(nmdcdb, coll_name)[0]  # get first instance (i.e. document) in list\n",
    "    newdoc_type: list[str] = class_hierarchy_as_list(exemplar)\n",
    "    \n",
    "    # For each document in this collection, replace the value of the `type` field with\n",
    "    # a _list_ of the document's own class and ancestor classes, remove the `_id` field,\n",
    "    # and insert the resulting document into the `alldocs` collection. Note that we are not\n",
    "    # relying on the original value of the `type` field, since it's unreliable (see below).\n",
    "    \n",
    "    # NOTE: `type` is currently a string, does not exist for all classes, and can have typos. \n",
    "    # Both of these are fixed in berkeley schema but is risky to use at this time\n",
    "\n",
    "    # TODO: Consider omitting fields that neither (a) are the `id` field, nor (b) have the potential\n",
    "    #       to reference a document. Those fields aren't related to referential integrity.\n",
    "    \n",
    "    mdb.alldocs.insert_many([assoc(dissoc(doc, 'type', '_id'), 'type', newdoc_type) for doc in mdb[coll_name].find()])\n",
    "    pbar.update(mdb[coll_name].estimated_document_count())\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Prior to re-ID-ing, some IDs are not unique across Mongo collections (eg nmdc:0078a0f981ad3f92693c2bc3b6470791)\n",
    "# Re-idx for `alldocs` collection\n",
    "mdb.alldocs.create_index(\"id\")\n",
    "print(\"refreshed `alldocs` collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0569fde",
   "metadata": {},
   "source": [
    "The resulting `alldocs` collection contains a copy of every document from every Mongo collection identified earlier. The copy is the same as the original document, except that its `type` field contains a list of the names of its own class and all of its ancestor classes (whereas, the original document's `type` field contains an unreliable string)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca194c0f-7417-41d2-bea8-a5a54392fee6",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab859bb2-808c-48e2-8412-d8a3a79ca4e8",
   "metadata": {},
   "source": [
    "Collect \"top level\" (`nmdc:Database` slot range) classes.\n",
    "\n",
    "Reference: https://linkml.io/linkml/developers/schemaview.html#linkml_runtime.utils.schemaview.SchemaView.class_ancestors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2dbaf22-46e9-4de7-8288-05bc8cd2e5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Activity',\n",
       " 'Biosample',\n",
       " 'BiosampleProcessing',\n",
       " 'CollectingBiosamplesFromSite',\n",
       " 'DataObject',\n",
       " 'Extraction',\n",
       " 'FieldResearchSite',\n",
       " 'FunctionalAnnotation',\n",
       " 'FunctionalAnnotationAggMember',\n",
       " 'GenomeFeature',\n",
       " 'LibraryPreparation',\n",
       " 'MagsAnalysisActivity',\n",
       " 'MaterialEntity',\n",
       " 'MetabolomicsAnalysisActivity',\n",
       " 'MetagenomeAnnotationActivity',\n",
       " 'MetagenomeAssembly',\n",
       " 'MetagenomeSequencingActivity',\n",
       " 'MetaproteomicsAnalysisActivity',\n",
       " 'MetatranscriptomeActivity',\n",
       " 'NamedThing',\n",
       " 'NomAnalysisActivity',\n",
       " 'OmicsProcessing',\n",
       " 'PlannedProcess',\n",
       " 'Pooling',\n",
       " 'ProcessedSample',\n",
       " 'ReadBasedTaxonomyAnalysisActivity',\n",
       " 'ReadQcAnalysisActivity',\n",
       " 'Site',\n",
       " 'Study',\n",
       " 'WorkflowExecutionActivity'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmdc_view = nmdc_schema_view()\n",
    "toplevel_classes = set()\n",
    "for name in nmdc_database_collection_instance_class_names():\n",
    "    # TODO: Document why class _ancestors_ are being included here.\n",
    "    #       A (hypothetical) collection whose range is \"Chihuahua\" wouldn't\n",
    "    #       be allowed to store non-\"Chihuahua\" instances of \"Dog\" or \"Animal\".\n",
    "    #\n",
    "    # Note: `a |= b` is same as `a = a | b` (union two sets and store the result).\n",
    "    #\n",
    "    toplevel_classes |= set(nmdc_view.class_ancestors(name))\n",
    "\n",
    "toplevel_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645690e-7a9d-4f1e-8e62-0cbdde825890",
   "metadata": {},
   "source": [
    "### Check referential integrity\n",
    "\n",
    "In this cell, we populate two lists:\n",
    "\n",
    "- `errors.not_found`: a list of \"naive\" errors\n",
    "- `errors.invalid_type`: a list of (hierarchy-aware) type errors (document was found, but is of an invalid type)\n",
    "\n",
    "Reference: https://linkml.io/linkml/developers/schemaview.html#linkml_runtime.utils.schemaview.SchemaView.class_induced_slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "103d70b6-24ab-41bd-8b7f-d2faaa028bdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe3e9398ee34917a6368718da059a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150019 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize error lists.\n",
    "errors = {\"not_found\": [], \"invalid_type\": []}\n",
    "\n",
    "# Initialize progress bar.\n",
    "#\n",
    "# TODO: Explain why the author has opted to count (and then—later—iterate over) the documents\n",
    "#       in the original collections, even though the `alldocs` collection exists already.\n",
    "#\n",
    "n_docs_total = sum(mdb[name].estimated_document_count() for name in collection_names)\n",
    "pbar = tqdm(total=n_docs_total)\n",
    "\n",
    "# Iterate over each collection name.\n",
    "for name in sorted(collection_names):\n",
    "    # Note: We already confirmed (in a different cell of this notebook)\n",
    "    #       that each `class_names` list has exactly one item.\n",
    "    cls_name = collection_name_to_class_names[name][0]\n",
    "    \n",
    "    # Make a dictionary of slot names to slot definitions. The set of slots here is (to quote the\n",
    "    # LinkML SchemaView documentation) \"all slots that are asserted or inferred for [the] class,\n",
    "    # with their inferred semantics.\"\n",
    "    slot_map = {\n",
    "        slot.name: slot\n",
    "        for slot in nmdc_view.class_induced_slots(cls_name)\n",
    "    }\n",
    "    pbar.set_description(f\"processing {name}...\")\n",
    "    \n",
    "    # Iterate over each document (as a dictionary) in this collection.\n",
    "    for doc in mdb[name].find():\n",
    "        doc = dissoc(doc, \"_id\")\n",
    "\n",
    "        # Iterate over each key/value pair in the dictionary (document).\n",
    "        for field, value in doc.items():\n",
    "            assert field in slot_map, f\"{name} doc {doc['id']}: field {field} not a valid slot\"\n",
    "            slot_range = str(slot_map[field].range)\n",
    "            assert slot_range, type(slot_range)\n",
    "            if not slot_range in toplevel_classes:\n",
    "                continue\n",
    "            if not isinstance(value, list):\n",
    "                value = [value]\n",
    "            for v in value:\n",
    "                if mdb.alldocs.find_one({\"id\": v}, [\"_id\"]) is None:\n",
    "                    errors[\"not_found\"].append(f\"{name} doc {doc['id']}: field {field} referenced doc {v} not found\")\n",
    "                elif mdb.alldocs.find_one({\"id\": v, \"type\": slot_range}, [\"_id\"]) is None:\n",
    "                    errors[\"invalid_type\"].append(f\"{name} doc {doc['id']}: field {field} referenced doc {v} not of type {slot_range}\")\n",
    "        pbar.update(1)\n",
    "pbar.close()           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2ce4a3-fb33-4b47-9c7f-a7919405ab65",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Display the number errors in each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e01450d1-3369-4fc5-80be-9787e00a6597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 20488)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors[\"not_found\"]), len(errors[\"invalid_type\"])\n",
    "# previous results: (4857, 23503)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a560df",
   "metadata": {},
   "source": [
    "Display a few errors from one of the lists, as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a25857f4-e26e-4896-9e5f-607e7b4bb07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mags_activity_set doc nmdc:wfmag-11-t8gc3c64.1: field has_input referenced doc nmdc:dobj-11-y2f0gn35 not found',\n",
       " 'mags_activity_set doc nmdc:wfmag-11-t8gc3c64.1: field has_input referenced doc nmdc:dobj-11-achfhn33 not found',\n",
       " 'mags_activity_set doc nmdc:wfmag-11-t8gc3c64.1: field has_input referenced doc nmdc:dobj-11-vt4jr220 not found',\n",
       " 'mags_activity_set doc nmdc:wfmag-11-0gwm7d87.1: field has_input referenced doc nmdc:dobj-11-9a9pn310 not found',\n",
       " 'mags_activity_set doc nmdc:wfmag-11-0gwm7d87.1: field has_input referenced doc nmdc:dobj-11-dpnhb305 not found']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors[\"not_found\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c7524",
   "metadata": {},
   "source": [
    "Spot check one of those errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "855e232d-0e94-428e-96eb-0535c5135bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdb.alldocs.find_one({\"id\": \"nmdc:dobj-11-y2f0gn35\"}) is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd191cd",
   "metadata": {},
   "source": [
    "Display a few errors from the other one of the lists, as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33516e3c-f10d-4c30-942b-0d01d06082f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_object_set doc nmdc:dobj-13-xx781m34: field was_generated_by referenced doc nmdc:omprc-13-4wkf0639 not of type Activity',\n",
       " 'data_object_set doc nmdc:dobj-13-9w8tgj98: field was_generated_by referenced doc nmdc:omprc-13-jsn1dv78 not of type Activity',\n",
       " 'data_object_set doc nmdc:dobj-13-mnptx531: field was_generated_by referenced doc nmdc:omprc-13-b93wt504 not of type Activity',\n",
       " 'data_object_set doc nmdc:dobj-13-gnaddy16: field was_generated_by referenced doc nmdc:omprc-13-vktqxb17 not of type Activity',\n",
       " 'data_object_set doc nmdc:dobj-13-r60zxs13: field was_generated_by referenced doc nmdc:omprc-13-f48rxk27 not of type Activity']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors[\"invalid_type\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4abec53",
   "metadata": {},
   "source": [
    "Spot check one of those errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29ec7e82-d079-4525-bd7b-d770fd69d788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('66748e9ff33c8467941f01b4'),\n",
       " 'id': 'nmdc:omprc-13-4wkf0639',\n",
       " 'name': 'Rachael_21T_04-15A_M_14Mar17_leopard_Infuse',\n",
       " 'instrument_name': '21T Agilent',\n",
       " 'has_input': ['nmdc:bsm-13-4bfysc34'],\n",
       " 'has_output': ['nmdc:dobj-13-xx781m34'],\n",
       " 'omics_type': {'has_raw_value': 'Organic Matter Characterization'},\n",
       " 'part_of': ['nmdc:sty-11-33fbta56'],\n",
       " 'description': 'High resolution MS spectra only',\n",
       " 'processing_institution': 'EMSL',\n",
       " 'gold_sequencing_project_identifiers': [],\n",
       " 'alternative_identifiers': ['emsl:570856'],\n",
       " 'type': ['OmicsProcessing', 'PlannedProcess', 'NamedThing']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OmicsProcessing is not subclass of Activity (!)\n",
    "mdb.alldocs.find_one({\"id\": \"nmdc:omprc-13-4wkf0639\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
