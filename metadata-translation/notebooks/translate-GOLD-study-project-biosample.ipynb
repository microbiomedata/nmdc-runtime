{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate GOLD study, project, and biosample data into json.\n",
    "The notebooks demostrates how to translate study, project, and biosample data from the GOLD database into json that conforms with the [NMDC schema](https://github.com/microbiomedata/nmdc-metadata/blob/schema-draft/README.md).  \n",
    "Before doing the translation it is important that you have an up to date `nmdc.py` file in the `lib` directory.  \n",
    "\n",
    "The python modules for running the notebook are in the `requirements.txt` file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('../src/bin/lib/')) # add path to lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pds\n",
    "import jsonasobj\n",
    "import nmdc\n",
    "import data_operations as dop\n",
    "from pandasql import sqldf\n",
    "\n",
    "def pysqldf(q):\n",
    "    return sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GOLD tables (i.e., tab delimited files) from nmdc zip file\n",
    "The NMDC data is currently stored in a zip file. Instead of unzipping the file, simply use the `zipfile` library to load the `study`, `project`, `contact`, `project_biosample`, and `biosample` tables (stored as tab-delimited files). The `project_biosample` table is needed as a cross-linking table between `project` and `biosample`. The `contact` table contains information about principal investigators.\n",
    "\n",
    "The code for unzipping and creating the dataframe is found in the `make_dataframe` function. As part of the dataframe creation process, the column names are lower cased and spaces are replaced with underscored. I find it helpful to have some standarization on column names when doing data wrangling. This behavior can be overridden if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = dop.make_dataframe(\"export.sql/STUDY_DATA_TABLE.dsv\", file_archive_name=\"../src/data/nmdc-version2.zip\")\n",
    "contact = dop.make_dataframe(\"export.sql/CONTACT_DATA_TABLE.dsv\", file_archive_name=\"../src/data/nmdc-version2.zip\")\n",
    "project = dop.make_dataframe(\"export.sql/PROJECT_DATA_TABLE.dsv\", file_archive_name=\"../src/data/nmdc-version2.zip\")\n",
    "project_biosample = dop.make_dataframe(\"export.sql/PROJECT_BIOSAMPLE_DATA_TABLE.dsv\", file_archive_name=\"../src/data/nmdc-version2.zip\")\n",
    "biosample = dop.make_dataframe(\"export.sql/BIOSAMPLE_DATA_TABLE.dsv\", file_archive_name=\"../src/data/nmdc-version2.zip\")\n",
    "proposals = dop.make_dataframe(\"../src/data/JGI-EMSL-FICUS-proposals.fnl.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset GOLD tables to records where active = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select \n",
    "    *\n",
    "from\n",
    "    study\n",
    "where\n",
    "    active = 'Yes'\n",
    "\"\"\"\n",
    "study = sqldf(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select \n",
    "    *\n",
    "from\n",
    "    project\n",
    "where\n",
    "    active = 'Yes'\n",
    "\"\"\"\n",
    "project = sqldf(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select \n",
    "    *\n",
    "from\n",
    "    biosample\n",
    "where\n",
    "    active = 'Yes'\n",
    "\"\"\"\n",
    "biosample = sqldf(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biosample.head() # peek at data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build json data files\n",
    "The json data files are build using a general approach:\n",
    "1. Create a pandas dataframe (often using SQL syntax) to be translated.\n",
    "2. Transform the dataframe into a dictionary (these variables end with '_dictdf')\n",
    "3. Define a list of field names whose names and values will be translated into characteristics within an annotation object.\n",
    "4. Pass the dataframe dictionary and characteristices list to the `make_json_string_list` method. This method returns a list of json ojbects each of which has been converted to a string.\n",
    "5. Save the json string to file using `save_json_string_list`.\n",
    "\n",
    "**Note:** Currently, I am using the GOLD IDs as idenifiers. This need to changed to IRIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build GOLD study json\n",
    "* Create a subset of the study table using the FICUS gold_ids specified in [JGI-EMSL-FICUS-proposals.fnl.xlxs](https://docs.google.com/spreadsheets/d/1sowTCYooDrOMq0ErD4s3xtgH3PLoxwa7/edit#gid=1363834365).\n",
    "* Follow approach for building json data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select \n",
    "    study.*, contact.name as principal_investigator_name, proposals.doi\n",
    "from\n",
    "    study\n",
    "left join\n",
    "    contact\n",
    "on\n",
    "    study.contact_id = contact.contact_id\n",
    "left join\n",
    "    proposals\n",
    "on\n",
    "    study.gold_id = proposals.gold_study\n",
    "where\n",
    "    study.gold_id in \n",
    "      ('Gs0110115', 'Gs0110132', 'Gs0112340', 'Gs0114675', 'Gs0128849', 'Gs0130354', \n",
    "       'Gs0114298', 'Gs0114663', 'Gs0120351', 'Gs0134277', 'Gs0133461', 'Gs0135152', 'Gs0135149')\n",
    "\"\"\"\n",
    "study = sqldf(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study.head() # peek at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_dictdf = study.to_dict(orient=\"records\") # transorm dataframe to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out a single record for viewing\n",
    "# for record in study_dictdf:\n",
    "#     print(json.dumps(record, indent=4)); break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "make_nmdc_dict_list() got an unexpected keyword argument 'characteristic_fields'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ddf4c10c6820>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m## create list of json string objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mstudy_json_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_json_string_list\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mstudy_dictdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gold_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'study_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"description\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacteristic_fields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcharacteristics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/NMDC/nmdc-metadata/metadata-translation/src/bin/lib/data_operations.py\u001b[0m in \u001b[0;36mmake_json_string_list\u001b[0;34m(dictionary, nmdc_class, id_key, name_key, description_key, part_of_key, has_input_key, has_output_key, characteristic_fields, remove_key_attributes)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mdict_list\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         make_nmdc_dict_list(dictionary, nmdc_class, id_key, name_key=name_key, description_key=description_key, part_of_key=part_of_key,\n\u001b[0;32m--> 171\u001b[0;31m                            has_input_key=has_input_key, has_output_key=has_output_key, characteristic_fields=characteristic_fields, remove_key_attributes=remove_key_attributes)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_dict_list_to_json_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: make_nmdc_dict_list() got an unexpected keyword argument 'characteristic_fields'"
     ]
    }
   ],
   "source": [
    "## specify characteristics\n",
    "characteristics = \\\n",
    "    ['gold_study_name', 'principal_investigator_name', 'add_date', 'mod_date', 'doi',\n",
    "      'ecosystem', 'ecosystem_category', 'ecosystem_type', 'ecosystem_subtype', 'specific_ecosystem', 'ecosystem_path_id']\n",
    "\n",
    "## create list of json string objects\n",
    "study_json_list = dop.make_json_string_list\\\n",
    "    (study_dictdf, nmdc.Study, id_key='gold_id', name_key='study_name', description_key=\"description\", characteristic_fields=characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(study_json_list[0]) ## peek at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dop.save_json_string_list(\"output/nmdc-json/study.json\", study_json_list) # save json string list to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buid GOLD project json\n",
    "* Create dataframe for projects that are part of the FICUS studies.\n",
    "* Add processing institution = 'Joint Genome Institute' to dataframe\n",
    "* Follow approach for building json data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select\n",
    "    project.*, project.sequencing_strategy as omics_type, study.gold_id as study_gold_id, contact.name as principal_investigator_name\n",
    "from \n",
    "    project\n",
    "inner join \n",
    "    study\n",
    "on \n",
    "    study.study_id = project.master_study_id\n",
    "left join\n",
    "    contact\n",
    "on\n",
    "    contact.contact_id = project.pi_id\n",
    "\"\"\"\n",
    "project = sqldf(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project[\"processing_institution\"] = \"Joint Genome Institute\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project.head() # peek at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dictdf = project.to_dict(orient=\"records\") # transorm dataframe to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify characteristics\n",
    "characteristics = \\\n",
    "    ['add_date', 'mod_date', 'completion_date', 'ncbi_project_name', 'omics_type', 'principal_investigator_name', 'processing_institution']\n",
    "\n",
    "## create list of json string objects\n",
    "project_json_list = dop.make_json_string_list\\\n",
    "    (project_dictdf, nmdc.OmicsProcessing, id_key='gold_id', name_key='project_name', \n",
    "     part_of_key=\"study_gold_id\", description_key=\"description\", characteristic_fields=characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(project_json_list[0]) ## peek at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dop.save_json_string_list(\"output/nmdc-json/omics_processing.json\", project_json_list) # save json string list to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build GOLD biosample json\n",
    "* Create dataframe for biosamples that are part of the FICUS studies. Note the use of `group_concat` in the query string. This is needed b/c a biosample may potentially belong to more than one project.\n",
    "* Follow approach for building json data files.\n",
    "\n",
    "**Note:** The list of characteristics is quite long. I might need to rething a more elegant way to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select\n",
    "    biosample.gold_id,\n",
    "    biosample.biosample_name,\n",
    "    biosample.description,\n",
    "    biosample.add_date,\n",
    "    biosample.mod_date,\n",
    "    biosample.ecosystem_path_id,\n",
    "    biosample.ecosystem,\n",
    "    biosample.ecosystem_category,\n",
    "    biosample.ecosystem_type,\n",
    "    biosample.ecosystem_subtype,\n",
    "    biosample.specific_ecosystem,\n",
    "    biosample.habitat,\n",
    "    biosample.location,\n",
    "    biosample.community,\n",
    "    biosample.ncbi_taxonomy_name,\n",
    "    biosample.geographic_location,\n",
    "    biosample.latitude,\n",
    "    biosample.longitude,\n",
    "    biosample.sample_collection_site,\n",
    "    biosample.identifier,\n",
    "    biosample.sample_collection_year,\n",
    "    biosample.sample_collection_month,\n",
    "    biosample.sample_collection_day,\n",
    "    biosample.sample_collection_hour,\n",
    "    biosample.sample_collection_minute,\n",
    "    biosample.host_name,\n",
    "    biosample.depth,\n",
    "    biosample.subsurface_depth,\n",
    "    biosample.altitude,\n",
    "    biosample.temperature_range,\n",
    "    biosample.proport_woa_temperature,\n",
    "    biosample.biogas_temperature,\n",
    "    biosample.growth_temperature,\n",
    "    biosample.soil_annual_season_temp,\n",
    "    biosample.water_samp_store_temp,\n",
    "    biosample.biogas_retention_time,\n",
    "    biosample.salinity,\n",
    "    biosample.pressure,\n",
    "    biosample.ph,\n",
    "    biosample.chlorophyll_concentration,\n",
    "    biosample.nitrate_concentration,\n",
    "    biosample.oxygen_concentration,\n",
    "    biosample.salinity_concentration,\n",
    "    group_concat(project.gold_id) as project_gold_ids\n",
    "from\n",
    "    biosample\n",
    "inner join project_biosample\n",
    "    on biosample.biosample_id = project_biosample.biosample_id\n",
    "inner join project\n",
    "    on project.project_id = project_biosample.project_id\n",
    "group by\n",
    "    biosample.biosample_id,\n",
    "    biosample.biosample_name,\n",
    "    biosample.description,\n",
    "    biosample.add_date,\n",
    "    biosample.mod_date,\n",
    "    biosample.ecosystem_path_id,\n",
    "    biosample.ecosystem,\n",
    "    biosample.ecosystem_category,\n",
    "    biosample.ecosystem_type,\n",
    "    biosample.ecosystem_subtype,\n",
    "    biosample.specific_ecosystem,\n",
    "    biosample.habitat,\n",
    "    biosample.location,\n",
    "    biosample.community,\n",
    "    biosample.ncbi_taxonomy_name,\n",
    "    biosample.geographic_location,\n",
    "    biosample.latitude,\n",
    "    biosample.longitude,\n",
    "    biosample.sample_collection_site,\n",
    "    biosample.identifier,\n",
    "    biosample.sample_collection_year,\n",
    "    biosample.sample_collection_month,\n",
    "    biosample.sample_collection_day,\n",
    "    biosample.sample_collection_hour,\n",
    "    biosample.sample_collection_minute,\n",
    "    biosample.host_name,\n",
    "    biosample.depth,\n",
    "    biosample.subsurface_depth,\n",
    "    biosample.altitude,\n",
    "    biosample.temperature_range,\n",
    "    biosample.proport_woa_temperature,\n",
    "    biosample.biogas_temperature,\n",
    "    biosample.growth_temperature,\n",
    "    biosample.soil_annual_season_temp,\n",
    "    biosample.water_samp_store_temp,\n",
    "    biosample.biogas_retention_time,\n",
    "    biosample.salinity,\n",
    "    biosample.pressure,\n",
    "    biosample.ph,\n",
    "    biosample.chlorophyll_concentration,\n",
    "    biosample.nitrate_concentration,\n",
    "    biosample.oxygen_concentration,\n",
    "    biosample.salinity_concentration\n",
    "\"\"\"\n",
    "biosampledf = sqldf(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biosample_dictdf = biosampledf.to_dict(orient=\"records\") # transorm dataframe to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify characteristics\n",
    "characteristics = \\\n",
    "    ['add_date',\n",
    "     'mod_date',\n",
    "     'ecosystem_path_id',\n",
    "     'ecosystem',\n",
    "     'ecosystem_category',\n",
    "     'ecosystem_type',\n",
    "     'ecosystem_subtype',\n",
    "     'specific_ecosystem',\n",
    "     'habitat',\n",
    "     'location',\n",
    "     'community',\n",
    "     'ncbi_taxonomy_name',\n",
    "     'geographic_location',\n",
    "     'latitude',\n",
    "     'longitude',\n",
    "     'sample_collection_site',\n",
    "     'identifier',\n",
    "     'sample_collection_year',\n",
    "     'sample_collection_month',\n",
    "     'sample_collection_day',\n",
    "     'sample_collection_hour',\n",
    "     'sample_collection_minute',\n",
    "     'host_name',\n",
    "     'depth',\n",
    "     'subsurface_depth',\n",
    "     'altitude',\n",
    "     'temperature_range',\n",
    "     'proport_woa_temperature',\n",
    "     'biogas_temperature',\n",
    "     'growth_temperature',\n",
    "     'soil_annual_season_temp',\n",
    "     'water_samp_store_temp',\n",
    "     'biogas_retention_time',\n",
    "     'salinity',\n",
    "     'pressure',\n",
    "     'ph',\n",
    "     'chlorophyll_concentration',\n",
    "     'nitrate_concentration',\n",
    "     'oxygen_concentration',\n",
    "     'salinity_concentration'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create list of json string objects\n",
    "biosample_json_list = dop.make_json_string_list\\\n",
    "    (biosample_dictdf, nmdc.Biosample, id_key='gold_id', name_key='biosample_name', \n",
    "     part_of_key=\"project_gold_ids\", description_key=\"description\", characteristic_fields=characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(biosample_json_list[0]) # peek at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dop.save_json_string_list(\"output/nmdc-json/biosample.json\", biosample_json_list) # save json string list to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
