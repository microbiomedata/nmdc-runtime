# This file contains a list of the direct (as opposed to transitive) production dependencies of
# the `nmdc_runtime` package. We use `pip-compile` (typically via `$ make update-deps`) to derive
# the "requirements.txt" file from this file.
#
# Reference: https://github.com/jazzband/pip-tools?tab=readme-ov-file#requirements-from-requirementsin
#
# Note: Here's a handy command you can use to find imports of the "foo" package in the codebase:
#       ```
#       $ grep -rE '(import|from)\s+.*foo' ./nmdc_runtime/
#       ```
#
# Note: To specify that a Python package be built from the contents of a GitHub repository (which can
#       be useful for integration testing before that Python package gets published to PyPI), you can
#       use the following syntax in this file:
#       ```
#       {package_name} @ git+https://github.com/{owner}/{repo}.git@{commit}
#       ```
#       For example:
#       ```
#       refscan @ git+https://github.com/microbiomedata/refscan.git@b4f6bab138d2158ece7ea2423a27d8b8493d02f5
#       ```
#
# TODO: Consider moving our "first-party" dependencies (e.g. `nmdc-schema`, `ontology-loader`, `refscan`)
#       to a group at the top of the file or a separate requirements file.
#
###############################################################################

# Note: We use this (imported via `base32_lib`) when minting IDs.
base32-lib
# Note: We use `boto3` to interact with S3-compatible storage services.
#       There is an open issue (nmdc-runtime/issues/512) about removing
#       the code that interacts with S3-compatible storage services, so
#       we might eventually remove this dependency.
boto3
# Note: We use `click` for some one-off scripts that generate changesheets (in `nmdc_runtime/site/changesheets/scripts/`)
#       and for scripts that were once used to dump, export, and restore MongoDB databases (in `nmdc_runtime/site/backup/`).
click
# Dagster-related packages.
# TODO: Maybe there's a new way to import Dagster's packages? See: https://docs.dagster.io/getting-started/installation#installation-requirements-for-manually-creating-or-updating-a-project
# TODO: Consider using SQLite instead of Postgres for Dagster. Related issue: nmdc-runtime/issues/885.
# Note: As some point, the only way to programmatically request that Dagster run something was via GraphQL. There may be another way now.
dagit
dagster
dagster-graphql
dagster-postgres
# Note: We use `fastapi` to implement the web application.
fastapi>=0.115.0  # note: FastAPI 0.115.0 introduced support for encapsulating request _query_ parameters in Pydantic models, including Swagger annotations
fastjsonschema
fnc
frozendict
git-root
jq
jsonasobj2
# TODO: Could these two Jupyter-related packages be made into development dependencies?
jupyter
jupyterlab
linkml
linkml-runtime
lxml
mkdocs-jupyter
mkdocs-material
mkdocs-mermaid2-plugin
ontology-loader==0.2.2
nmdc-schema==11.10.0
pandas
passlib[bcrypt]
pymongo
pydantic[email]>=1.10.0
# Note: We use `pyinstrument` for performance profiling.
#       Docs https://pyinstrument.readthedocs.io/en/latest/guide.html#profile-a-web-request-in-fastapi
pyinstrument
python-dotenv
python-jose[cryptography]
# Note: python-multipart version `0.0.18` introduced a patch for a security issue (CVE-2024-53981).
#       Reference: https://github.com/microbiomedata/nmdc-runtime/security/dependabot/8
python-multipart>=0.0.18
pyyaml
# Note: We use `refscan` to get information about inter-document references from the schema and database.
#       Reference: https://pypi.org/project/refscan/
refscan==0.3.2
requests
# Note: We use `scalar-fastapi` to integrate Scalar API documentation with FastAPI.
# Note: We use a Git URL to install the `scalar-fastapi` package, because the Scalar
#       maintainers have not published recent versions of the package to PyPI yet.
# Reference: https://github.com/scalar/scalar/issues/5337#issuecomment-2781011096
# Modern API documentation interface for FastAPI
scalar-fastapi@git+https://github.com/scalar/scalar/#subdirectory=integrations/fastapi
semver
setuptools-scm
tenacity
toolz
tqdm
uvicorn[standard]
requests-cache
